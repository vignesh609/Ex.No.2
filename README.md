
# Ex.No: 2 	Evaluation of 2024 Prompting Tools Across Diverse AI Platforms: ChatGPT, Claude, Bard, Cohere Command, and Meta 
### DATE:                                                                            
### REGISTER NUMBER : 
 
### Aim:
To compare the performance, user experience, and response quality of different AI platforms (ChatGPT, Claude, Bard, Cohere Command, and Meta) within a specific use case, such as summarizing text or answering technical questions. Generate a Prompt based output using different Prompting tools of 2024.
### AI Tools required:

### Explanation:
Define the Use Case:
Select a specific task for evaluation across platforms (e.g., summarizing a document, answering a technical question, or generating a creative story / Code).
Ensure the use case is applicable to all platforms and will allow for comparison across response quality, accuracy, and depth.
Create a Set of Prompts:
Prepare a uniform set of prompts that align with the chosen use case.
Each prompt should be clear and precise, ensuring that all platforms are evaluated using the same input.
Consider multiple prompts to capture the versatility of each platform in handling different aspects of the use case.
Run the Experiment on Each AI Platform:
Input the prompts into each AI tool (ChatGPT, Claude, Bard, Cohere Command, and Meta) and gather the responses.
Ensure the same conditions are applied for each platform, such as input format, time to respond, and prompt delivery.
Record response times, ease of interaction with the platform, and any technical issues encountered.
Evaluate Response Quality:
Assess each platformâ€™s responses using the following criteria: Accuracy,Clarity,Depth,Relevance 
Compare Performance:
Compare the collected data to identify differences in performance across platforms.
Identify any platform-specific advantages, such as faster response times, more accurate answers, or more intuitive interfaces.
Deliverables:
A comparison table outlining the performance of each platform (ChatGPT, Claude, Bard, Cohere Command, and Meta) based on accuracy, clarity, depth, and relevance of responses.
A final report summarizing the findings of the experiment, including recommendations on the most suitable AI platform for different use cases based on performance and user 

### Output:

### Conclusion: 


# Result : The Prompt for the above problem statement executed successfully.

# EX-02-Cross-Platform-Prompting-Evaluating-Diverse-Techniques-in-AI-Powered-Text-Summarization

## AIM
To evaluate and compare the effectiveness of prompting techniques (zero-shot, few-shot, chain-of-thought, role-based) across different AI platforms (e.g., ChatGPT, Gemini, Claude, Copilot) in a specific task: text summarization.

## Scenario:
You are part of a content curation team for an educational platform that delivers quick summaries of research papers to undergraduate students. Your task is to summarize a 500-word technical article on "The Basics of Blockchain Technology" using multiple AI platforms and prompting strategies.

Your goal is to determine which combination of prompting technique + platform provides the best summary in terms of:

Accuracy

Coherence

Simplicity

Speed

User experience

## Algorithm

## Result

Aim

To study prompt engineering techniques in generative AI, compare their effectiveness across leading AI platforms, and evaluate user experience and performance.

Tools Required

AI Platforms: OpenAI ChatGPT, Anthropic Claude, Google Gemini (Bard), Cohere Command, Meta LLaMA.

Prompting Techniques: Zero-shot, Few-shot, Role-based prompting, Chain-of-thought prompting.

Evaluation Metrics: Accuracy of output, relevance, creativity, clarity, and response time.

Introduction to Prompting Tools in AI Platforms

Prompt engineering is the practice of designing clear and structured inputs to guide AI models toward producing accurate and useful responses. Since Large Language Models (LLMs) rely heavily on prompts, the same query may give different results depending on how it is phrased.

Each platform offers slightly different behaviors:

OpenAI ChatGPT: Excels in reasoning and creativity.

Anthropic Claude: Strong in safety and contextual understanding.

Google Gemini (Bard): Well-integrated with real-time web information.

Cohere Command: Focused on enterprise-scale NLP tasks.

Meta LLaMA: Open-source and customizable for research.

Prompt engineering helps standardize comparisons and ensures better outputs from these platforms.

Methodology of Comparison

Selection of Prompts: A set of 10 prompts covering summarization, creative writing, problem-solving, and factual accuracy.

Testing Across Platforms: Each prompt was tested on the five AI platforms using zero-shot, few-shot, and role-based techniques.

Evaluation Criteria:

Accuracy of Information

Creativity of Output

Response Speed

Ease of Use

User Experience

Result Comparison Table
<img width="873" height="384" alt="Screenshot 2025-08-25 201827" src="https://github.com/user-attachments/assets/44560a25-3938-464e-975e-68300ebbd261" />

Performance and User Experience

ChatGPT provided the most balanced performance across creativity, reasoning, and ease of interaction.

Claude excelled in safe and ethical outputs but was less creative in storytelling.

Gemini integrated real-time data effectively but sometimes lacked depth in reasoning.

Cohere was useful for technical NLP but not as user-friendly for casual tasks.

LLaMA, being open-source, offered flexibility but required technical setup, making it less accessible for beginners.

Conclusion and Result

Prompt engineering plays a critical role in maximizing the performance of AI platforms. Clear, role-based, and example-rich prompts yield better results than vague queries. Among the tested platforms, ChatGPT scored highest for overall performance, while Claude and Gemini provided strong alternatives depending on user priorities (safety vs. real-time information). For researchers, LLaMA remains valuable due to its open-source flexibility, and Cohere fits enterprise-specific NLP needs.

Final Result: Prompt engineering is essential for improving output quality, and ChatGPT currently provides the best balance between usability, accuracy, and creativity.
<img width="1536" height="1024" alt="ChatGPT Image Aug 25, 2025, 07_56_04 PM" src="https://github.com/user-attachments/assets/e893ebf4-b5fd-494d-aece-ba8fa0e95c0c" />
